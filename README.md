# Image Enhancement Project Structure

- `low_light/`

  Low-light image enhancement

  *Independent implementation by Hansheng Zhang*
- `dehaze/`
  
  Image dehazing

  *Independent implementation by Ruolan Shi*
- `derain/`
  
  Image deraining
  
  *Independent implementation by Liang Yang*

---
  
# PART A: LOW-LIGHT IMAGE ENHANCEMENT (Contributor: Hansheng Zhang)

This repository implements a framework for low-light image enhancement, comparing CLAHE and Retinex. It includes tools for processing images and analyzing performance metrics.

## Requirements

To run the code, you need Python installed along with the following libraries:

```bash
pip install numpy opencv-python pandas matplotlib seaborn pyyaml tqdm
```

## Data Setup

### 1. LOL Dataset

You can download the LOL (Low-Light) dataset from Kaggle:

- **Download Link**: [LOL Dataset on Kaggle](https://www.kaggle.com/datasets/soumikrakshit/lol-dataset)

After downloading, organize the data in the `data/` directory. For example:

- `data/raw/lol_low`: Low-light images
- `data/raw/lol_high`: High-light (Ground Truth) images

### 2. iPhone Photos

A set of low-light photos taken with an iPhone will be uploaded to this repository.

- Place these images in `data/raw/iphone` (or verify their location in the repository).

## Configuration

The project is configured via `config.yaml`. You can modify this file to change input/output directories and algorithm parameters. All **relative paths** in `config.yaml` are resolved relative to the location of the `config.yaml` file.

**Key Configuration Options:**

- **`data`**:

  - `input_dir`: Directory containing input low-light images (e.g., `"data/raw/iphone"`).
  - `gt_dir`: (Optional) Directory containing ground truth images for metric calculation (e.g., `"data/raw/lol_high"`).
  - `output_dir`: Directory where enhanced images and metrics will be saved.
- **`algorithms`**: List of algorithms to run (e.g., `['clahe', 'retinex']`).
- **`analysis`**:

  - `metrics_file`: Path to the CSV file generated by `main.py` (e.g., `"data/results/iphone/metrics.csv"`).
  - `output_dir`: Directory to save analysis plots and summaries.

## How to Run

### 1. Run Image Enhancement

To process images using the configured algorithms, please go to the directory **`low_light/`** and run:

```bash
python main.py
```

This script will:

- Read images from `input_dir`.
- Apply selected algorithms.
- Save enhanced images to `output_dir`.
- specific metrics (PSNR, SSIM, etc. if GT is available) and runtime will be saved to a `metrics.csv` file in the `output_dir`.

### 2. Analyze Results

To generate plots and summary statistics from the metrics:

1. Ensure the `metrics_file` path in `config.yaml` under the `analysis` section points to the `metrics.csv` generated in the previous step.
2. Run the analysis script:

```bash
python analyze_metrics.py
```

This will generate visualizations (boxplots, bar charts) and a summary CSV in the `analysis/output_dir`.

## Output

- **Enhanced Images**: Saved in the configured `output_dir`.
- **Metrics**: A `metrics.csv` file inside the `output_dir`.
- **Analysis**: Plots and summary tables in the `analysis_results` folder.

---

# PART B: IMAGE DEHAZING

This module provides a **unified and reproducible evaluation pipeline** for classical image dehazing methods on both **benchmark datasets with ground truth** and **real-world hazy images without reference**.

The design emphasizes:

- Clear separation of dehazing methods
- Reproducible evaluation and comparison
- A lightweight repository (datasets and pretrained weights are not tracked)

## Implemented Methods

The following image dehazing methods are implemented and evaluated:

- **CLAHE**Contrast Limited Adaptive Histogram Equalization
- **DCP**Dark Channel Prior
- **RIDCP**
  Refinement-based Image Dehazing via Dark Channel Prior

## External Code Attribution (RIDCP)

The RIDCP implementation used in this project is adapted from the following open-source repository:

- **RQ-Wu et al., RIDCP Dehazing**
  https://github.com/RQ-Wu/RIDCP_dehazing

Only the **core RIDCP code** is included under: dehaze/external/RIDCP_dehazing/

The following components from the original repository are excluded:

1. Datasets
2. Pretrained weights
3. Result folders

This keeps the repository lightweight and focused on evaluation.

## Datasets and Data Preparation

This repository does **not** include datasets or pretrained weights.
All data must be downloaded and placed locally.

### I-HAZE and O-HAZE (With Ground Truth)

The I-HAZE and O-HAZE datasets are used for **full-reference quantitative evaluation**, including:

- PSNR
- SSIM
- Color difference ΔE₀₀

**I-HAZE (Indoor scenes)**
https://data.vision.ee.ethz.ch/cvl/ntire18/i-haze/

**O-HAZE (Outdoor scenes)**
https://data.vision.ee.ethz.ch/cvl/ntire18/o-haze/

Expected directory layout after downloading:

```text
dehaze/data/raw/ihaze/
├── hazy/
└── gt/

dehaze/data/raw/ohaze/
├── hazy/
└── gt/
```

## How to Run

All scripts should be executed **from the repository root** to ensure correct module imports.

Before running any script, make sure that:

- Required datasets are downloaded and placed in the expected directories
- RIDCP pretrained weights are available if running RIDCP
- The Python environment is properly set up

### 1. Setup Environment

Install dependencies

### 2. Run Dehazing on Benchmark Datasets

The following scripts run dehazing methods on the **I-HAZE** and **O-HAZE** datasets and compute **full-reference metrics** (PSNR, SSIM, ΔE₀₀).

Run **CLAHE**:

```bash
python dehaze/scripts/run_clahe.py
```

Run **DCP**:

```bash
python dehaze/scripts/run_dcp.py
```

Run **RIDCP**:
(make sure pretrained weights are placed under dehaze/external/RIDCP_dehazing/pretrained_models/):

```bash
python dehaze/scripts/run_ridcp.py
```

### 3. Run Evaluation on Real-World Images (No Reference)

Real-world hazy images are evaluated using the **BRISQUE** no-reference quality metric.

Place images under:

```text
dehaze/data/real_haze/
```

Run evaluation:

```text
python dehaze/scripts/run_realworld.py
```

Generate combined comparison tables and plots:

```text
python dehaze/scripts/analyze_realworld.py
```

### 4. Generate Comparison Tables and Plots

After running all methods, you can generate aggregated comparison results.

Merge per-method metrics:

```bash
python dehaze/scripts/compare_all.py
```

Generate comparison plots (PSNR / SSIM / ΔE):

```bash
python dehaze/scripts/plot_all.py
```

### 5. License and Acknowledgements

- **Revitalizing Real Image Dehazing via High-Quality Codebook Priors (RIDCP)**:https://github.com/RQ-Wu/RIDCP_dehazing
- **I-HAZE / O-HAZE datasets**:I-HAZE: https://data.vision.ee.ethz.ch/cvl/ntire18/i-haze/

  O-HAZE: https://data.vision.ee.ethz.ch/cvl/ntire18/o-haze/


---

# PART C: IMAGE DERAIN (Contributor: Liang Yang)

This part compares a fast classical baseline (Guided Filter) with a learning–based Progressive Residual Network (PRN) on four public rain-removal benchmark datasets.
All code and notebooks live in `derain/`.

## 1. Download Dataset and Place them to the Correct Directory

In order to run the image derain project, please download the dataset from the link provided, and place the unzip data into the corresponding directory mentioned in the "Dataset Processing Notes" column

**(Note: Please ensure the datasets are placed in correct directory, otherwise, the code DOES NOT work)**

| Dataset                            | Split(s)                     | Download link                                                                                                                   | Dataset Processing Notes                                                                                                                                                                                                                                       |
| ---------------------------------- | ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Rain100L&nbsp;/ Rain100H** | test                         | [Rain Dataset on Kaggle](https://www.kaggle.com/datasets/bshaurya/rain-dataset/data)                                               | Extract the `input/` and `target/` folders within the unzip Rain100L and Rain100H file to `derain/data/Rain100L/input/` and `derain/data/Rain100L/target/`, `derain/data/Rain100H/input/` and `derain/data/Rain100H/target/` correspondingly  |
| **Rain200L**                 | train&nbsp;/&nbsp;validation | [Baidu Netdisk Download link ](https://pan.baidu.com/s/1rTb4qU3fCEA4MRpQss__DA?pwd=s2yx) (Extraction Code: `s2yx`)              | Download using the "Extraction Code", and extract the `input/` and `target/` folders within the unzip Rain200L file to `derain/data/Rain200L/train/input/` and `derain/data/Rain200L/train/target/` correspondingly                                 |
| **Rain200H**                 | train&nbsp;/&nbsp;validation | [Baidu Netdisk Download link ](https://pan.baidu.com/share/init?surl=KK8R2bPKgcOX8gMXSuKtCQ&pwd=z9br) (Extraction Code: `z9br`) | Download using the "Extraction Code", and extract the `input/` and `target/` folders within the unzip Rain200H file to `derain/data/Rain200H/train/input/` and `derain/data/Rain200H/train/target/` correspondingly                                  |

## 2. Dependencies checklist

| Package                                        | Purpose                                                          |
| ---------------------------------------------- | ---------------------------------------------------------------- |
| **Python ≥ 3.8**                        | Programming language                                             |
| **torch** ≥ 2.0 & **torchvision** | core deep-learning runtime (used by PRN)                         |
| **numpy**                                | array math (shared by both GF & PRN)                             |
| **opencv-contrib-python**                | fast Guided Filter (`cv2.ximgproc.guidedFilter`) and image I/O |
| **pillow**                               | lightweight image decoding in the PRN dataloader                 |
| **scikit-image**                         | reference PSNR / SSIM metrics                                    |
| **matplotlib**                           | quick visualisation utilities inside the notebooks               |
| **tqdm**                                 | progress bars during PRN training/inference                      |

## 3. Run the Code

The source code scripts and the complete data pipeline (Data preprocessing, model training and model inferencing and evaluation) for both PRN and Guided Filter are arranged in Python Jupyter Notebook.

The code for Guided Filter is in `derain/derain_gf.ipynb`

The code for PRN is in `derain/derain_prn.ipynb`

Run the notebooks cell-by-cell and end-to-end to reproduce the results and see the output images

## 4. Outputs

Running the derain notebooks `derain/derain_gf.ipynb` and `derain/derain_prn.ipyn` will create this folder tree (for clarity, we already create this tree structure):

```text
derain/
└── output/
    ├── gf/                  # store Guided-Filter results on the Rain 100L/H dataset
    │   ├── rain100L/        # *.png (light-rain set)
    │   └── rain100H/        # *.png (heavy-rain set)
    ├── prn/                 # store PRN results on the Rain 100L/H dataset
    │   ├── rain100L/
    │   └── rain100H/
    └── metrics/             # store CSV evaluaition metrics reports (PSNR / SSIM)

```
