{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef172213",
   "metadata": {},
   "source": [
    "# Data preprocessing & dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, subprocess\n",
    "print(\"cuda_available:\", torch.cuda.is_available())\n",
    "print(\"num_gpus:\", torch.cuda.device_count())\n",
    "print(\"name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Data preprocessing & dataloaders (single-file, no argparse, flat configs)\n",
    "# ============================================================\n",
    "import os, math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----------------------\n",
    "# Minimal flat \"config\"\n",
    "# ----------------------\n",
    "# === Test sets & example output (as you requested) ===\n",
    "RAIN100H_INP_DIR = \"data/rain100H/input\"    # 只包含 .png 雨图\n",
    "RAIN100H_GT_DIR  = \"data/rain100H/target\"\n",
    "RAIN100L_INP_DIR = \"data/rain100L/input\"\n",
    "RAIN100L_GT_DIR  = \"data/rain100L/target\"\n",
    "OUT_DIR_GF       = \"output/gf\"              # 示例：GF 输出保存处（本段代码不使用）\n",
    "\n",
    "# === Train sets ===  (按你之前描述：从 Rain200L/H 各取 400 组 [100.png-499.png])\n",
    "# 若你的实际文件夹是大写(Rain200L)，把这两行改成相应大小写\n",
    "RAIN200L_TRAIN_INP_DIR = \"data/Rain200L/train/input\"\n",
    "RAIN200L_TRAIN_GT_DIR  = \"data/Rain200L/train/target\"\n",
    "RAIN200H_TRAIN_INP_DIR = \"data/Rain200H/train/input\"\n",
    "RAIN200H_TRAIN_GT_DIR  = \"data/Rain200H/train/target\"\n",
    "\n",
    "# === Split & reproducibility ===\n",
    "VAL_PERCENT         = 0.15     # 15% 作为验证集\n",
    "SEED                = 3407\n",
    "\n",
    "# === Preprocess / Augment ===\n",
    "TRAIN_PATCH_SIZE    = 128      # 训练用随机裁剪 patch\n",
    "USE_PATCH_TRAIN     = True\n",
    "AUG_FLIP            = True     # 随机水平/垂直翻转\n",
    "AUG_ROT90           = True     # 随机 90° 旋转\n",
    "VAL_USE_FULL_IMAGE  = True     # 验证用整图；如显存紧张可设为 False\n",
    "VAL_CENTER_CROP     = 256      # 仅在 VAL_USE_FULL_IMAGE=False 时使用\n",
    "\n",
    "# === Dataloader ===\n",
    "BATCH_SIZE          = 8\n",
    "NUM_WORKERS         = 0        # macOS/M1 推荐 0 或 2\n",
    "PIN_MEMORY          = False\n",
    "\n",
    "# === Metrics 统一设置（PRN / GF 都使用） ===\n",
    "METRIC_USE_Y_CHANNEL = True   # 指标用 Y 通道\n",
    "METRIC_SHAVE_PIXELS  = 4      # 统一 shave 边缘像素数；如需更严格对齐可设 4/8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efe667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Utils\n",
    "# ----------------------\n",
    "def set_global_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def _is_image_file(name: str) -> bool:\n",
    "    return os.path.splitext(name)[1].lower() in [\".png\", \".jpg\", \".jpeg\", \".bmp\"]\n",
    "\n",
    "def list_paired_samples(dir_input: str, dir_target: str) -> List[Tuple[str, str, str]]:\n",
    "    \"\"\"\n",
    "    返回按文件名排序的 (input_path, target_path, basename) 列表，只保留两侧都存在的配对。\n",
    "    \"\"\"\n",
    "    assert os.path.isdir(dir_input), f\"Not found: {dir_input}\"\n",
    "    assert os.path.isdir(dir_target), f\"Not found: {dir_target}\"\n",
    "    names = [n for n in os.listdir(dir_input) if _is_image_file(n)]\n",
    "\n",
    "    pairs = []\n",
    "    for n in names:\n",
    "        ip = os.path.join(dir_input, n)\n",
    "        tp = os.path.join(dir_target, n)\n",
    "        if os.path.isfile(tp):\n",
    "            pairs.append((ip, tp, n))\n",
    "\n",
    "    def key_fn(x):\n",
    "        base = os.path.splitext(x[2])[0]\n",
    "        try:\n",
    "            return int(base)    # 让 100.png < 101.png …\n",
    "        except:\n",
    "            return x[2]\n",
    "    pairs.sort(key=key_fn)\n",
    "    return pairs\n",
    "\n",
    "def split_train_val(\n",
    "    pairs: List[Tuple[str, str, str]],\n",
    "    val_percent: float,\n",
    "    by_tail: bool = True,\n",
    "    seed: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    训练/验证划分。\n",
    "    默认 by_tail=True：取“按文件名排序后的尾部 val%”为验证集（简单稳定、可复现）。\n",
    "    如果更喜欢随机划分：by_tail=False，并提供 seed。\n",
    "    \"\"\"\n",
    "    assert 0.0 < val_percent < 1.0\n",
    "    n = len(pairs)\n",
    "    k = int(math.ceil(n * val_percent))\n",
    "    if by_tail:\n",
    "        return pairs[: n - k], pairs[n - k :]\n",
    "    else:\n",
    "        rng = random.Random(seed)\n",
    "        idx = list(range(n))\n",
    "        rng.shuffle(idx)\n",
    "        val_set = set(idx[:k])\n",
    "        tr, va = [], []\n",
    "        for i, p in enumerate(pairs):\n",
    "            (va if i in val_set else tr).append(p)\n",
    "        return tr, va\n",
    "\n",
    "# ----------------------\n",
    "# Tensor transforms\n",
    "# ----------------------\n",
    "def pil_to_tensor(img: Image.Image) -> torch.Tensor:\n",
    "    arr = np.array(img, dtype=np.float32) / 255.0\n",
    "    if arr.ndim == 2:  # 灰度\n",
    "        arr = np.expand_dims(arr, -1)\n",
    "    arr = arr.transpose(2, 0, 1)  # HWC -> CHW\n",
    "    return torch.from_numpy(arr)\n",
    "\n",
    "def random_crop_pair(inp: torch.Tensor, tgt: torch.Tensor, size: int, rng: random.Random):\n",
    "    _, H, W = inp.shape\n",
    "    if H < size or W < size:\n",
    "        pad_h, pad_w = max(0, size - H), max(0, size - W)\n",
    "        inp = torch.nn.functional.pad(inp, (0, pad_w, 0, pad_h), mode=\"reflect\")\n",
    "        tgt = torch.nn.functional.pad(tgt, (0, pad_w, 0, pad_h), mode=\"reflect\")\n",
    "        _, H, W = inp.shape\n",
    "    y = rng.randint(0, H - size)\n",
    "    x = rng.randint(0, W - size)\n",
    "    return inp[:, y:y+size, x:x+size], tgt[:, y:y+size, x:x+size]\n",
    "\n",
    "def random_flip_rotate_pair(inp: torch.Tensor, tgt: torch.Tensor, rng: random.Random, flip=True, rot90=True):\n",
    "    if flip:\n",
    "        if rng.random() < 0.5:  # 水平翻转\n",
    "            inp = torch.flip(inp, dims=[2]); tgt = torch.flip(tgt, dims=[2])\n",
    "        if rng.random() < 0.5:  # 垂直翻转\n",
    "            inp = torch.flip(inp, dims=[1]); tgt = torch.flip(tgt, dims=[1])\n",
    "    if rot90 and rng.random() < 0.5:\n",
    "        k = rng.choice([1, 2, 3])\n",
    "        inp = torch.rot90(inp, k, dims=[1, 2]); tgt = torch.rot90(tgt, k, dims=[1, 2])\n",
    "    return inp, tgt\n",
    "\n",
    "def center_crop_pair(inp: torch.Tensor, tgt: torch.Tensor, size: int):\n",
    "    _, H, W = inp.shape\n",
    "    if H < size or W < size:\n",
    "        pad_h, pad_w = max(0, size - H), max(0, size - W)\n",
    "        inp = torch.nn.functional.pad(inp, (0, pad_w, 0, pad_h), mode=\"reflect\")\n",
    "        tgt = torch.nn.functional.pad(tgt, (0, pad_w, 0, pad_h), mode=\"reflect\")\n",
    "        _, H, W = inp.shape\n",
    "    y = (H - size) // 2\n",
    "    x = (W - size) // 2\n",
    "    return inp[:, y:y+size, x:x+size], tgt[:, y:y+size, x:x+size]\n",
    "\n",
    "import torch\n",
    "\n",
    "def rgb_to_y(img: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    img: [B,3,H,W] in [0,1] (sRGB 假设)\n",
    "    返回: [B,1,H,W] Y 通道（BT.601, Studio Range 简化为 0..1）\n",
    "    公式来源（系数常用）：Y = 0.299 R + 0.587 G + 0.114 B\n",
    "    \"\"\"\n",
    "    assert img.ndim == 4 and img.size(1) == 3, \"rgb_to_y expects [B,3,H,W]\"\n",
    "    r, g, b = img[:, 0:1, :, :], img[:, 1:2, :, :], img[:, 2:2+1, :, :]\n",
    "    y = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    return y.clamp(0.0, 1.0)\n",
    "\n",
    "def crop_border(img: torch.Tensor, shave: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    img: [B,C,H,W]; 在 H/W 维度裁掉边缘 shave 个像素\n",
    "    \"\"\"\n",
    "    if shave <= 0:\n",
    "        return img\n",
    "    return img[:, :, shave:-shave, shave:-shave]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Dataset\n",
    "# ----------------------\n",
    "@dataclass\n",
    "class SampleItem:\n",
    "    input_path: str\n",
    "    target_path: str\n",
    "    name: str\n",
    "    subset: str  # e.g., \"Rain200L\", \"Rain100H\"\n",
    "\n",
    "class RainPairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    mode:\n",
    "      - \"train\": 随机裁剪 + 轻量增强\n",
    "      - \"val\"  : 整图 or 中心裁剪，无随机增强\n",
    "      - \"test\" : 整图，保留 target 以便后续算指标\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        samples: List[SampleItem],\n",
    "        mode: str,\n",
    "        train_patch_size: int = TRAIN_PATCH_SIZE,\n",
    "        use_patch_train: bool = USE_PATCH_TRAIN,\n",
    "        aug_flip: bool = AUG_FLIP,\n",
    "        aug_rot90: bool = AUG_ROT90,\n",
    "        val_use_full_image: bool = VAL_USE_FULL_IMAGE,\n",
    "        val_center_crop: int = VAL_CENTER_CROP,\n",
    "        seed: int = SEED,\n",
    "    ):\n",
    "        assert mode in [\"train\", \"val\", \"test\"]\n",
    "        self.samples = samples\n",
    "        self.mode = mode\n",
    "        self.train_patch_size = train_patch_size\n",
    "        self.use_patch_train = use_patch_train\n",
    "        self.aug_flip = aug_flip\n",
    "        self.aug_rot90 = aug_rot90\n",
    "        self.val_use_full_image = val_use_full_image\n",
    "        self.val_center_crop = val_center_crop\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def _load_pair(self, input_path: str, target_path: Optional[str]):\n",
    "        inp = Image.open(input_path).convert(\"RGB\")\n",
    "        inp_t = pil_to_tensor(inp)\n",
    "        tgt_t = None\n",
    "        if target_path is not None and os.path.isfile(target_path):\n",
    "            tgt = Image.open(target_path).convert(\"RGB\")\n",
    "            tgt_t = pil_to_tensor(tgt)\n",
    "        return inp_t, tgt_t\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        it = self.samples[idx]\n",
    "        inp_t, tgt_t = self._load_pair(it.input_path, it.target_path)\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            if self.use_patch_train:\n",
    "                inp_t, tgt_t = random_crop_pair(inp_t, tgt_t, self.train_patch_size, self.rng)\n",
    "            if self.aug_flip or self.aug_rot90:\n",
    "                inp_t, tgt_t = random_flip_rotate_pair(inp_t, tgt_t, self.rng, self.aug_flip, self.aug_rot90)\n",
    "\n",
    "        elif self.mode == \"val\":\n",
    "            if not self.val_use_full_image:\n",
    "                inp_t, tgt_t = center_crop_pair(inp_t, tgt_t, self.val_center_crop)\n",
    "\n",
    "        # \"test\": 保持整图\n",
    "        return {\n",
    "            \"input\": inp_t, \"target\": tgt_t,\n",
    "            \"name\": it.name, \"subset\": it.subset,\n",
    "            \"input_path\": it.input_path, \"target_path\": it.target_path\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Builders\n",
    "# ----------------------\n",
    "def build_train_val_datasets():\n",
    "    set_global_seed(SEED)\n",
    "\n",
    "    # Rain200L\n",
    "    L_pairs = list_paired_samples(RAIN200L_TRAIN_INP_DIR, RAIN200L_TRAIN_GT_DIR)\n",
    "    L_tr, L_va = split_train_val(L_pairs, VAL_PERCENT, by_tail=True, seed=SEED)\n",
    "    L_tr_items = [SampleItem(ip, tp, n, \"Rain200L\") for ip, tp, n in L_tr]\n",
    "    L_va_items = [SampleItem(ip, tp, n, \"Rain200L\") for ip, tp, n in L_va]\n",
    "\n",
    "    # Rain200H\n",
    "    H_pairs = list_paired_samples(RAIN200H_TRAIN_INP_DIR, RAIN200H_TRAIN_GT_DIR)\n",
    "    H_tr, H_va = split_train_val(H_pairs, VAL_PERCENT, by_tail=True, seed=SEED)\n",
    "    H_tr_items = [SampleItem(ip, tp, n, \"Rain200H\") for ip, tp, n in H_tr]\n",
    "    H_va_items = [SampleItem(ip, tp, n, \"Rain200H\") for ip, tp, n in H_va]\n",
    "\n",
    "    train_ds = RainPairDataset(L_tr_items + H_tr_items, mode=\"train\")\n",
    "    val_ds   = RainPairDataset(L_va_items + H_va_items, mode=\"val\")\n",
    "\n",
    "    print(f\"[Data] Rain200L total={len(L_pairs)} | train={len(L_tr_items)} | val={len(L_va_items)}\")\n",
    "    print(f\"[Data] Rain200H total={len(H_pairs)} | train={len(H_tr_items)} | val={len(H_va_items)}\")\n",
    "    print(f\"[Data] Combined train={len(train_ds)} | val={len(val_ds)}\")\n",
    "    return train_ds, val_ds\n",
    "\n",
    "def build_train_val_loaders():\n",
    "    train_ds, val_ds = build_train_val_datasets()\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=1 if VAL_USE_FULL_IMAGE else BATCH_SIZE, shuffle=False,\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def build_test_datasets():\n",
    "    L_pairs = list_paired_samples(RAIN100L_INP_DIR, RAIN100L_GT_DIR)\n",
    "    H_pairs = list_paired_samples(RAIN100H_INP_DIR, RAIN100H_GT_DIR)\n",
    "    testL = RainPairDataset([SampleItem(ip, tp, n, \"Rain100L\") for ip, tp, n in L_pairs], mode=\"test\")\n",
    "    testH = RainPairDataset([SampleItem(ip, tp, n, \"Rain100H\") for ip, tp, n in H_pairs], mode=\"test\")\n",
    "    print(f\"[Data] Rain100L test={len(testL)} | Rain100H test={len(testH)}\")\n",
    "    return testL, testH\n",
    "\n",
    "def build_test_loaders():\n",
    "    testL, testH = build_test_datasets()\n",
    "    testL_loader = DataLoader(testL, batch_size=1, shuffle=False,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)\n",
    "    testH_loader = DataLoader(testH, batch_size=1, shuffle=False,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)\n",
    "    return testL_loader, testH_loader\n",
    "\n",
    "# ----------------------\n",
    "# Quick sanity check (可按需启用)\n",
    "# ----------------------\n",
    "tl, vl = build_train_val_loaders()\n",
    "b = next(iter(tl))\n",
    "print(\"[Peek][train]\", b[\"input\"].shape, b[\"target\"].shape, b[\"input\"].min().item(), b[\"input\"].max().item())\n",
    "b = next(iter(vl))\n",
    "print(\"[Peek][val]\", b[\"input\"].shape, b[\"target\"].shape, b[\"input\"].min().item(), b[\"input\"].max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b289113",
   "metadata": {},
   "source": [
    "# PRN Model (Progressive Residual Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PRN Model (Progressive Residual Network, lightweight)\n",
    "#  - 多阶段渐进细化（T 个阶段）\n",
    "#  - 采用残差预测：x̂_t = x̂_{t-1} + f([y, x̂_{t-1}])\n",
    "#  - 可选阶段间权重共享（节省参数/显存）\n",
    "#  - 适合 M1: C=32, T=6, 每阶段 5 个 ResBlock\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --------\n",
    "# 模型配置（扁平变量）\n",
    "# --------\n",
    "PRN_T_STAGES        = 6     # 阶段数\n",
    "PRN_BASE_CHANNELS   = 32    # 主干通道\n",
    "PRN_NUM_RESBLOCKS   = 5     # 每阶段 ResBlock 个数\n",
    "PRN_WEIGHT_SHARING  = True  # 阶段间共享主干\n",
    "PRN_USE_RESIDUAL    = True  # 预测残差而非直接输出\n",
    "PRN_CLAMP_OUTPUT    = True  # 将输出裁剪到 [0,1]（训练/推理都安全）\n",
    "\n",
    "# --------\n",
    "# 基础模块\n",
    "# --------\n",
    "def kaiming_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "class ConvReLU(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=p)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.apply(kaiming_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(ch, ch, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(ch, ch, 3, 1, 1)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.apply(kaiming_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        idt = x\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        return self.relu(out + idt)\n",
    "\n",
    "class PRNBackbone(nn.Module):\n",
    "    \"\"\"\n",
    "    单个阶段的主干（可被多个阶段共享）：\n",
    "      输入通道数 = 6（concat: y 与 x_prev）\n",
    "      输出通道数 = 3（预测残差或预测图像）\n",
    "    结构：Conv3x3 -> N*ResBlock -> Conv3x3\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=32, num_blocks=5, in_ch=6, out_ch=3):\n",
    "        super().__init__()\n",
    "        layers = [ConvReLU(in_ch, base_ch, 3, 1, 1)]\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(ResBlock(base_ch))\n",
    "        self.trunk = nn.Sequential(*layers)\n",
    "        self.head  = nn.Conv2d(base_ch, out_ch, 3, 1, 1)\n",
    "        kaiming_init(self.head)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.trunk(x)\n",
    "        return self.head(feat)\n",
    "\n",
    "class PRN(nn.Module):\n",
    "    \"\"\"\n",
    "    Progressive Residual Network（无循环状态，轻量稳定）\n",
    "      - forward(y) 返回：\n",
    "          outputs_all: [x̂_1, x̂_2, ..., x̂_T]  （深度监督可用）\n",
    "          output:      x̂_T（最终输出）\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        T=PRN_T_STAGES,\n",
    "        base_ch=PRN_BASE_CHANNELS,\n",
    "        num_blocks=PRN_NUM_RESBLOCKS,\n",
    "        weight_sharing=PRN_WEIGHT_SHARING,\n",
    "        use_residual=PRN_USE_RESIDUAL,\n",
    "        clamp_out=PRN_CLAMP_OUTPUT\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.use_residual = use_residual\n",
    "        self.clamp_out = clamp_out\n",
    "\n",
    "        if weight_sharing:\n",
    "            self.shared = PRNBackbone(base_ch, num_blocks, in_ch=6, out_ch=3)\n",
    "            self.stages = None\n",
    "        else:\n",
    "            self.shared = None\n",
    "            self.stages = nn.ModuleList(\n",
    "                [PRNBackbone(base_ch, num_blocks, in_ch=6, out_ch=3) for _ in range(T)]\n",
    "            )\n",
    "\n",
    "    def _stage_block(self, t: int):\n",
    "        return self.shared if self.shared is not None else self.stages[t]\n",
    "\n",
    "    @staticmethod\n",
    "    def _concat(y, x_prev):\n",
    "        # [B,3,H,W] cat [B,3,H,W] => [B,6,H,W]\n",
    "        return torch.cat([y, x_prev], dim=1)\n",
    "\n",
    "    def forward(self, y: torch.Tensor):\n",
    "        \"\"\"\n",
    "        y: 带雨图像，范围建议在 [0,1]，shape [B,3,H,W]\n",
    "        \"\"\"\n",
    "        x_prev = y\n",
    "        outputs = []\n",
    "        for t in range(self.T):\n",
    "            inp = self._concat(y, x_prev)\n",
    "            res_or_img = self._stage_block(t)(inp)\n",
    "            if self.use_residual:\n",
    "                x_cur = x_prev + res_or_img\n",
    "            else:\n",
    "                x_cur = res_or_img\n",
    "            if self.clamp_out:\n",
    "                x_cur = torch.clamp(x_cur, 0.0, 1.0)\n",
    "            outputs.append(x_cur)\n",
    "            x_prev = x_cur\n",
    "        return {\"all\": outputs, \"final\": outputs[-1]}\n",
    "\n",
    "# -------------\n",
    "# 构建/统计工具\n",
    "# -------------\n",
    "def build_prn():\n",
    "    \"\"\"\n",
    "    统一的模型构建函数；若后续想换配置，改上面的扁平变量即可。\n",
    "    \"\"\"\n",
    "    model = PRN(\n",
    "        T=PRN_T_STAGES,\n",
    "        base_ch=PRN_BASE_CHANNELS,\n",
    "        num_blocks=PRN_NUM_RESBLOCKS,\n",
    "        weight_sharing=PRN_WEIGHT_SHARING,\n",
    "        use_residual=PRN_USE_RESIDUAL,\n",
    "        clamp_out=PRN_CLAMP_OUTPUT,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# ----------------------\n",
    "# (Optional) quick model sanity\n",
    "# ----------------------\n",
    "m = build_prn()\n",
    "print(m)\n",
    "x = torch.rand(2, 3, 128, 128)  # B=2\n",
    "y = m(x)\n",
    "print(\"params(M):\", count_parameters(m)/1e6)\n",
    "print(\"outs:\", len(y[\"all\"]), y[\"final\"].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde44c9",
   "metadata": {},
   "source": [
    "# Losses, Metrics, Train/Val Loop, Test & Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a918bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Losses, Metrics, Train/Val Loop, Test & Saving (single-file)\n",
    "# ============================================================\n",
    "import time, csv\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------\n",
    "# 训练/验证/测试超参（扁平变量）\n",
    "# ----------------------\n",
    "EPOCHS             = 120\n",
    "LR                 = 1e-4\n",
    "WEIGHT_DECAY       = 0.0\n",
    "LR_MILESTONES      = [72, 96]   # 与 3 小时目标匹配的衰减点，可按需调整\n",
    "LR_GAMMA           = 0.2\n",
    "EARLY_STOP_PATIENCE= 12         # 监控验证 SSIM 的早停\n",
    "SAVE_DIR_CKPT      = \"checkpoints\"\n",
    "CKPT_BEST_PATH     = os.path.join(SAVE_DIR_CKPT, \"prn_best.pth\")\n",
    "CKPT_LAST_PATH     = os.path.join(SAVE_DIR_CKPT, \"prn_last.pth\")\n",
    "\n",
    "# PRN 输出目录（按题意）\n",
    "PRN_OUT_DIR_L      = \"output/prn/rain100L\"\n",
    "PRN_OUT_DIR_H      = \"output/prn/rain100H\"\n",
    "\n",
    "# 深度监督与损失权重\n",
    "USE_DEEP_SUPERVISION = True\n",
    "LAMBDA_SSIM          = 0.2      # Loss = L1 + LAMBDA_SSIM * (1-SSIM)\n",
    "DS_WEIGHTS_MODE      = \"equal\"  # \"equal\" 或 \"last_heavier\"\n",
    "DS_LAST_EXTRA        = 1.0      # 当 last_heavier 时，最后一阶段的额外权重\n",
    "\n",
    "# AMP（混合精度）在 mps/cuda 上启用\n",
    "USE_AMP = True\n",
    "\n",
    "# ----------------------\n",
    "# Metrics: PSNR / SSIM\n",
    "# ----------------------\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _gaussian_window(window_size: int, sigma: float, device, channels: int):\n",
    "    coords = torch.arange(window_size, dtype=torch.float32, device=device) - window_size // 2\n",
    "    g = torch.exp(- (coords ** 2) / (2 * sigma * sigma))\n",
    "    g = (g / g.sum()).unsqueeze(1)\n",
    "    window_2d = g @ g.t()                       # [w, w]\n",
    "    window_2d = window_2d.expand(channels, 1, window_size, window_size)\n",
    "    return window_2d\n",
    "\n",
    "def ssim_torch(x: torch.Tensor, y: torch.Tensor, window_size: int = 11, sigma: float = 1.5):\n",
    "    \"\"\"\n",
    "    x,y: [B,C,H,W] in [0,1]，C 可为 1 或 3\n",
    "    返回: [B] 的 SSIM\n",
    "    \"\"\"\n",
    "    assert x.shape == y.shape, \"SSIM expects same shape\"\n",
    "    device = x.device\n",
    "    C = x.size(1)\n",
    "    window = _gaussian_window(window_size, sigma, device, channels=C)\n",
    "    C1 = (0.01 ** 2)\n",
    "    C2 = (0.03 ** 2)\n",
    "\n",
    "    mu_x = F.conv2d(x, window, groups=C, padding=window_size//2)\n",
    "    mu_y = F.conv2d(y, window, groups=C, padding=window_size//2)\n",
    "    sigma_x  = F.conv2d(x * x, window, groups=C, padding=window_size//2) - mu_x ** 2\n",
    "    sigma_y  = F.conv2d(y * y, window, groups=C, padding=window_size//2) - mu_y ** 2\n",
    "    sigma_xy = F.conv2d(x * y, window, groups=C, padding=window_size//2) - mu_x * mu_y\n",
    "\n",
    "    ssim_map = ((2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)) / \\\n",
    "               ((mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2))\n",
    "    # 对通道取均值，再对空间取均值\n",
    "    ssim_val = ssim_map.mean(dim=[1,2,3])\n",
    "    return ssim_val\n",
    "\n",
    "\n",
    "def psnr_torch(x: torch.Tensor, y: torch.Tensor, eps: float = 1e-8):\n",
    "    \"\"\"\n",
    "    x,y: [B,3,H,W] in [0,1]\n",
    "    \"\"\"\n",
    "    mse = F.mse_loss(x, y, reduction='none').mean(dim=[1,2,3])  # [B]\n",
    "    psnr = -10.0 * torch.log10(mse + eps)\n",
    "    return psnr\n",
    "\n",
    "# ----------------------\n",
    "# Loss with Deep Supervision\n",
    "# ----------------------\n",
    "def prn_loss(outputs: dict, target: torch.Tensor):\n",
    "    \"\"\"\n",
    "    outputs: {\"all\": [x1, x2, ..., xT], \"final\": xT}\n",
    "    target : clean image [B,3,H,W] in [0,1]\n",
    "    \"\"\"\n",
    "    outs = outputs[\"all\"] if USE_DEEP_SUPERVISION else [outputs[\"final\"]]\n",
    "    T = len(outs)\n",
    "    if DS_WEIGHTS_MODE == \"equal\":\n",
    "        weights = [1.0 / T] * T\n",
    "    elif DS_WEIGHTS_MODE == \"last_heavier\":\n",
    "        base = 1.0 / (T - 1 + DS_LAST_EXTRA)\n",
    "        weights = [base] * (T - 1) + [base * DS_LAST_EXTRA]\n",
    "    else:\n",
    "        weights = [1.0 / T] * T\n",
    "\n",
    "    total = 0.0\n",
    "    for w, pred in zip(weights, outs):\n",
    "        l1 = F.l1_loss(pred, target)\n",
    "        ssim_val = ssim_torch(pred, target).mean()\n",
    "        loss = l1 + LAMBDA_SSIM * (1.0 - ssim_val)\n",
    "        total = total + w * loss\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3318f",
   "metadata": {},
   "source": [
    "# Model Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 设备选择 & AMP context\n",
    "# ----------------------\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def amp_autocast(device):\n",
    "    if not USE_AMP:\n",
    "        from contextlib import nullcontext\n",
    "        return nullcontext()\n",
    "    if device.type == \"cuda\":\n",
    "        return torch.autocast(device_type=\"cuda\", dtype=torch.float16)\n",
    "    if device.type == \"mps\":\n",
    "        return torch.autocast(device_type=\"mps\", dtype=torch.float16)\n",
    "    # cpu 不用 AMP\n",
    "    from contextlib import nullcontext\n",
    "    return nullcontext()\n",
    "\n",
    "# ----------------------\n",
    "# 训练与验证\n",
    "# ----------------------\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "def train_one_epoch(model, optimizer, scaler, train_loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    n = 0\n",
    "    t0 = time.time()\n",
    "    for batch in train_loader:\n",
    "        inp = batch[\"input\"].to(device, non_blocking=False)\n",
    "        tgt = batch[\"target\"].to(device, non_blocking=False)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp_autocast(device):\n",
    "            out = model(inp)\n",
    "            loss = prn_loss(out, tgt)\n",
    "\n",
    "        if USE_AMP and device.type in (\"cuda\", \"mps\"):\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inp.size(0)\n",
    "        n += inp.size(0)\n",
    "\n",
    "    return running_loss / max(1, n), time.time() - t0\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    验证阶段：\n",
    "      - loss 仍用 RGB（与训练一致）\n",
    "      - 指标(PSNR/SSIM)统一到 Y 通道 + shave = METRIC_SHAVE_PIXELS\n",
    "      - 返回: 验证集平均 loss、PSNR、SSIM、耗时\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    psnr_list, ssim_list = [], []\n",
    "    n = 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for batch in val_loader:\n",
    "        inp = batch[\"input\"].to(device, non_blocking=False)   # [B,3,H,W], 0..1\n",
    "        tgt = batch[\"target\"].to(device, non_blocking=False)  # [B,3,H,W], 0..1\n",
    "\n",
    "        # 前向与损失（RGB）\n",
    "        with amp_autocast(device):\n",
    "            out = model(inp)\n",
    "            loss = prn_loss(out, tgt)   # RGB 上的 L1+SSIM 组合损失\n",
    "            pred = out[\"final\"]         # [B,3,H,W], 0..1\n",
    "\n",
    "        # 累计平均 loss（按样本数加权）\n",
    "        bs = inp.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "\n",
    "        # ---- 指标：Y 通道 + shave ----\n",
    "        ref_eval  = tgt\n",
    "        pred_eval = pred\n",
    "        if METRIC_USE_Y_CHANNEL:\n",
    "            ref_eval  = rgb_to_y(ref_eval)   # -> [B,1,H,W]\n",
    "            pred_eval = rgb_to_y(pred_eval)  # -> [B,1,H,W]\n",
    "        if METRIC_SHAVE_PIXELS > 0:\n",
    "            ref_eval  = crop_border(ref_eval,  METRIC_SHAVE_PIXELS)\n",
    "            pred_eval = crop_border(pred_eval, METRIC_SHAVE_PIXELS)\n",
    "\n",
    "        psnr_list.append(psnr_torch(pred_eval, ref_eval))   # [B]\n",
    "        ssim_list.append(ssim_torch(pred_eval, ref_eval))   # [B]\n",
    "\n",
    "    avg_loss = total_loss / max(1, n)\n",
    "    avg_psnr = torch.cat(psnr_list).mean().item() if psnr_list else 0.0\n",
    "    avg_ssim = torch.cat(ssim_list).mean().item() if ssim_list else 0.0\n",
    "    return avg_loss, avg_psnr, avg_ssim, time.time() - t0\n",
    "\n",
    "\n",
    "def fit_prn():\n",
    "    # 准备目录\n",
    "    Path(SAVE_DIR_CKPT).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 数据\n",
    "    train_loader, val_loader = build_train_val_loaders()\n",
    "\n",
    "    # 模型 & 设备\n",
    "    device = get_device()\n",
    "    model = build_prn().to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=LR_MILESTONES, gamma=LR_GAMMA)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(USE_AMP and device.type in (\"cuda\", \"mps\")))  # mps 也可用此 scaler\n",
    "\n",
    "    print(f\"[Device] {device} | params: {count_parameters(model)/1e6:.3f} M\")\n",
    "    best_ssim = -1.0\n",
    "    best_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        tr_loss, tr_time = train_one_epoch(model, optimizer, scaler, train_loader, device)\n",
    "        val_loss, val_psnr, val_ssim, val_time = validate(model, val_loader, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"[Epoch {epoch:03d}] \"\n",
    "              f\"train_loss={tr_loss:.4f} ({tr_time:.1f}s) | \"\n",
    "              f\"val_loss={val_loss:.4f} psnr={val_psnr:.2f} ssim={val_ssim:.4f} ({val_time:.1f}s) | \"\n",
    "              f\"lr={optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        # 保存 last\n",
    "        torch.save({\"epoch\": epoch,\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"scheduler\": scheduler.state_dict(),\n",
    "                    \"ssim\": val_ssim}, CKPT_LAST_PATH)\n",
    "\n",
    "        # 选优（以验证 SSIM）\n",
    "        if val_ssim > best_ssim:\n",
    "            best_ssim = val_ssim\n",
    "            best_state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"scheduler\": scheduler.state_dict(),\n",
    "                \"ssim\": val_ssim\n",
    "            }\n",
    "            torch.save(best_state, CKPT_BEST_PATH)\n",
    "            print(f\"  -> New best (SSIM={best_ssim:.4f}), saved to {CKPT_BEST_PATH}\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= EARLY_STOP_PATIENCE:\n",
    "                print(f\"  -> Early stopping at epoch {epoch} (no improve {epochs_no_improve} epochs).\")\n",
    "                break\n",
    "\n",
    "    print(f\"[Train Done] best_val_ssim={best_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0211a3",
   "metadata": {},
   "source": [
    "# Model Inference & Save Results & Metric Calculations on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cdf697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 推理 & 保存结果 & 计算指标 (测试集)\n",
    "# ----------------------\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference_and_save(model, loader, out_dir: str, device):\n",
    "    \"\"\"\n",
    "    测试/推理阶段：\n",
    "      - 保存 PRN 输出（RGB PNG）\n",
    "      - 指标(PSNR/SSIM)统一到 Y 通道 + shave = METRIC_SHAVE_PIXELS\n",
    "      - 生成 metrics.csv（逐图 + 均值）\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    rows = [(\"name\", \"psnr\", \"ssim\")]\n",
    "    psnr_all, ssim_all = [], []\n",
    "\n",
    "    model.eval()\n",
    "    for batch in loader:\n",
    "        inp = batch[\"input\"].to(device)   # [1,3,H,W]\n",
    "        tgt = batch[\"target\"].to(device)  # [1,3,H,W]\n",
    "        name = batch[\"name\"][0]           # 文件名，如 \"1.png\"\n",
    "\n",
    "        # 前向\n",
    "        with amp_autocast(device):\n",
    "            out = model(inp)\n",
    "            pred = out[\"final\"]           # [1,3,H,W], 0..1\n",
    "\n",
    "        # 保存预测图（RGB）\n",
    "        save_path = os.path.join(out_dir, name)\n",
    "        save_image(pred.clamp(0, 1), save_path)\n",
    "\n",
    "        # ---- 指标：Y 通道 + shave ----\n",
    "        ref_eval  = tgt\n",
    "        pred_eval = pred\n",
    "        if METRIC_USE_Y_CHANNEL:\n",
    "            ref_eval  = rgb_to_y(ref_eval)    # [1,1,H,W]\n",
    "            pred_eval = rgb_to_y(pred_eval)   # [1,1,H,W]\n",
    "        if METRIC_SHAVE_PIXELS > 0:\n",
    "            ref_eval  = crop_border(ref_eval,  METRIC_SHAVE_PIXELS)\n",
    "            pred_eval = crop_border(pred_eval, METRIC_SHAVE_PIXELS)\n",
    "\n",
    "        psnr = psnr_torch(pred_eval, ref_eval).item()\n",
    "        ssimv = ssim_torch(pred_eval, ref_eval).item()\n",
    "\n",
    "        rows.append((name, f\"{psnr:.4f}\", f\"{ssimv:.4f}\"))\n",
    "        psnr_all.append(psnr)\n",
    "        ssim_all.append(ssimv)\n",
    "\n",
    "    # 写 metrics.csv（含均值）\n",
    "    mean_psnr = sum(psnr_all) / len(psnr_all) if psnr_all else 0.0\n",
    "    mean_ssim = sum(ssim_all) / len(ssim_all) if ssim_all else 0.0\n",
    "    rows.append((\"AVERAGE\", f\"{mean_psnr:.4f}\", f\"{mean_ssim:.4f}\"))\n",
    "\n",
    "    metrics_csv = os.path.join(out_dir, \"metrics.csv\")\n",
    "    with open(metrics_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"[Test] Saved to {out_dir} | PSNR={mean_psnr:.3f} SSIM={mean_ssim:.4f}\")\n",
    "\n",
    "\n",
    "def test_prn_on_rain100():\n",
    "    device = get_device()\n",
    "    # 加载 best\n",
    "    assert os.path.isfile(CKPT_BEST_PATH), f\"Best checkpoint not found: {CKPT_BEST_PATH}\"\n",
    "    ckpt = torch.load(CKPT_BEST_PATH, map_location=\"cpu\")\n",
    "    model = build_prn().to(device)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    print(f\"[Load] {CKPT_BEST_PATH} (epoch={ckpt.get('epoch','?')}, ssim={ckpt.get('ssim','-')})\")\n",
    "\n",
    "    # 数据\n",
    "    testL_loader, testH_loader = build_test_loaders()\n",
    "\n",
    "    # 推理并保存\n",
    "    inference_and_save(model, testL_loader, PRN_OUT_DIR_L, device)\n",
    "    inference_and_save(model, testH_loader, PRN_OUT_DIR_H, device)\n",
    "\n",
    "# ----------------------\n",
    "# （可选）一键运行：先训后测\n",
    "# ----------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     fit_prn()               # 训练，保存 best/last\n",
    "#     test_prn_on_rain100()   # 加载 best 在 Rain100L/H 上评测并落盘"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "derain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
